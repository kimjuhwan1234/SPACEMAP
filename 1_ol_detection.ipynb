{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:52.018812700Z",
     "start_time": "2024-08-07T04:15:51.999821300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:52.185656900Z",
     "start_time": "2024-08-07T04:15:52.179456600Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_CUSUM(X):\n",
    "    CUSUM = np.cumsum(X ** 2)\n",
    "    return CUSUM\n",
    "\n",
    "\n",
    "def compute_gamma(X, T, m):\n",
    "    mean_X = np.mean(X)\n",
    "    r = X - mean_X  # 잔차 계산\n",
    "    r_squared = r ** 2\n",
    "    sigma_squared = np.mean(r_squared)\n",
    "\n",
    "    gamma = np.zeros(m + 1)\n",
    "    for i in range(0, m + 1):\n",
    "        gamma_i = np.sum((r_squared[i:T] - sigma_squared) * (r_squared[0:T - i] - sigma_squared))\n",
    "        gamma[i] = gamma_i / T\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def compute_lambda(gamma, m):\n",
    "    lambda_hat = gamma[0] + 2 * np.sum((1 - np.arange(1, m + 1) / (m + 1)) * gamma[1:m + 1])\n",
    "    return lambda_hat\n",
    "\n",
    "\n",
    "def compute_D_prime(CUSUM, T, lambda_hat):\n",
    "    k = np.arange(T)\n",
    "    D_prime = (CUSUM - (k + 1) / T * CUSUM[-1]) / np.sqrt(lambda_hat)\n",
    "    return D_prime\n",
    "\n",
    "\n",
    "def compute_percentile(D_prime, T, percent=95):\n",
    "    D_prime_abs = np.abs(D_prime) * np.sqrt(T / 2)\n",
    "    critical_value = np.percentile(D_prime_abs, percent)\n",
    "    return critical_value"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def set_plot_params(title, ylabel):\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.xlabel(\"Date\", fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.xticks(rotation=30, fontsize=12)\n",
    "    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(30))\n",
    "\n",
    "\n",
    "def calculate_ylim(data):\n",
    "    ylim_min = min(data) - (max(data) - min(data)) * 0.1\n",
    "    ylim_max = max(data) + (max(data) - min(data)) * 0.1\n",
    "    return ylim_min, ylim_max\n",
    "\n",
    "\n",
    "def draw_graph(data: pd.DataFrame, title: str, ylabel: str, date_lst: list, color=\"blue\"):\n",
    "    '''\n",
    "    :param data: 시간 인덱스와 그래프로 표시할 정보가 있는 데이터프레임\n",
    "    :param title: 그래프 제목\n",
    "    :param ylabel: 그래프 y축 단위\n",
    "    :param date_lst: 아웃라이어 날짜인덱스 리스트\n",
    "    :param color: 그래프 색깔\n",
    "    :return: \n",
    "    '''\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, data.values, color=color)\n",
    "    for date in date_lst:\n",
    "        plt.axvline(pd.to_datetime(date), color='red', linestyle='--', label='Highlight Date')\n",
    "    set_plot_params(title, ylabel)\n",
    "    ylim_min, ylim_max = calculate_ylim(list(data.values))\n",
    "    plt.ylim(ylim_min, ylim_max)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:52.390233700Z",
     "start_time": "2024-08-07T04:15:52.379566600Z"
    }
   },
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:52.739197Z",
     "start_time": "2024-08-07T04:15:52.727688Z"
    }
   },
   "outputs": [],
   "source": [
    "def ol_detect(hour_df, diff_value, window_size, significant_level, number):\n",
    "    lambda_lst = []\n",
    "    cv_lst = []\n",
    "    current_lst = []\n",
    "    ol_lst = []\n",
    "\n",
    "    for i in tqdm(range(window_size, len(diff_value) + 1, 1)):\n",
    "\n",
    "        count = 0\n",
    "        filter = []\n",
    "        for val in ol_lst:\n",
    "            if (i - window_size <= val) and (val < i):\n",
    "                count += 1\n",
    "                filter.append(val - (i))\n",
    "\n",
    "        X = diff_value[i - window_size - count: i].copy()\n",
    "\n",
    "        if len(filter) != 0:\n",
    "            X = np.delete(X, filter)\n",
    "\n",
    "        N = len(X)\n",
    "        T = N\n",
    "        m = int(T ** (1 / 4))\n",
    "\n",
    "        # CUSUM 계산\n",
    "        CUSUM = compute_CUSUM(X)\n",
    "        # gamma 계산\n",
    "        gamma = compute_gamma(X, T, m)\n",
    "        # lambda_hat 계산\n",
    "        lambda_hat = compute_lambda(gamma, m)\n",
    "        lambda_lst.append(lambda_hat)\n",
    "        # D_prime 계산\n",
    "        D_prime = compute_D_prime(CUSUM, T, lambda_hat)\n",
    "        # critical value 계산\n",
    "        critical_value = compute_percentile(D_prime, T, significant_level)\n",
    "        cv_lst.append(critical_value)\n",
    "        # 현재 통계량 계산\n",
    "        current_lst.append(np.abs(D_prime[-2]) * np.sqrt(T / 2))\n",
    "\n",
    "        if current_lst[-1] > critical_value:\n",
    "            ol_lst.append(i - 1)\n",
    "\n",
    "    ol_lst = list(np.where((np.array(current_lst) > np.array(cv_lst)))[0] + window_size)\n",
    "    print(len(ol_lst))\n",
    "\n",
    "    plt.figure(figsize=(13, 2), dpi=400)\n",
    "    plt.plot(hour_df[name], color='tab:blue')\n",
    "\n",
    "    for point in ol_lst:\n",
    "        plt.axvline(hour_df.index[point], color='tab:red', linewidth=0.5, linestyle='--')\n",
    "        plt.scatter(hour_df.index[point], hour_df[name].iloc[point], color='tab:red', s=10)\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('KM')  # y축 레이블과 단위\n",
    "    # plt.savefig(f'File/images/{number}/{window}_{level}.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 0 missing files in File/images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "input_dir = 'Database'\n",
    "output_dir = 'File/images'\n",
    "\n",
    "number_lst = [39227, 44343, 44349, 44350, 44351, 44353, 44358, 58464, 46267, 53611, 53019, 51961, 47775, 51969, 58722,\n",
    "              56361, 56289, 56783, 48018, 43823, 45246, 29349, 37265, 42691, 42984, 55841]\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of files that do not exist in the output directory\n",
    "missing_dirs = [str(file) for file in number_lst if not os.path.exists(f\"{output_dir}/{file}\")]\n",
    "\n",
    "# Create missing files\n",
    "for directory in missing_dirs:\n",
    "    dir_path = os.path.join(output_dir, directory)\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "print(f\"Created {len(missing_dirs)} missing files in {output_dir}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:53.793196200Z",
     "start_time": "2024-08-07T04:15:53.778219900Z"
    }
   },
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LEO_lst = [39227, 44343, 44349, 44350, 44351, 44353, 44358, 58464, 46267, 53611, 53019, 51961, 47775, 51969, 58722,\n",
    "           56361, 56289, 56783, 48018]\n",
    "GEO_lst = [43823, 45246, 29349, 37265, 42691, 42984, 55841]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-07T04:15:54.938841200Z",
     "start_time": "2024-08-07T04:15:54.919395500Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Old"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for number in LEO_lst:\n",
    "    name = 'perigee'\n",
    "    info_df = pd.read_csv(f'Database/{number}.csv')\n",
    "    df_1 = info_df.copy()\n",
    "    df_1.loc[:, 'time'] = pd.to_datetime(df_1[['year', 'month', 'day', 'hour', 'minute']])\n",
    "    df_1.set_index('time', inplace=True)\n",
    "    df_1.drop(columns=['year', 'month', 'day', 'hour', 'minute'], inplace=True)\n",
    "    hour_df = df_1[::60].copy()\n",
    "    diff_value = np.log(hour_df[name].copy()).diff().fillna(0).values\n",
    "\n",
    "    for level in [95, 99]:\n",
    "        for window in [24 * 7 * 1, 24 * 7 * 2, 24 * 7 * 4]:\n",
    "            print(f'number: {number}, window : {window}, level : {level}')\n",
    "            ol_detect(hour_df, diff_value, window, level, number)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for number in GEO_lst:\n",
    "    name = 'longitude'\n",
    "    info_df = pd.read_csv(f'Database/{number}.csv')\n",
    "\n",
    "    df_1 = info_df.copy()\n",
    "    df_1.loc[:, 'time'] = pd.to_datetime(df_1[['year', 'month', 'day', 'hour', 'minute']])\n",
    "    df_1 = df_1[df_1.index > '2022-12-31 23:59:59'].copy()\n",
    "    df_1.set_index('time', inplace=True)\n",
    "    df_1.drop(columns=['year', 'month', 'day', 'hour', 'minute'], inplace=True)\n",
    "    hour_df = df_1[::60].copy()\n",
    "    diff_value = np.log(hour_df[name].copy()).diff().fillna(0).values\n",
    "\n",
    "    for level in [95, 99]:\n",
    "        for window in [24 * 7 * 1, 24 * 7 * 2, 24 * 7 * 4]:\n",
    "            print(f'number: {number}, window : {window}, level : {level}')\n",
    "            ol_detect(hour_df, diff_value, window, level, number)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing New"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for number in LEO_lst:\n",
    "    name = 'perigee'\n",
    "    info_df = pd.read_csv(f'Database/{number}_new.csv', index_col=0)\n",
    "    info_df = info_df[info_df.index > '2022-12-31 23:59:59'].copy()\n",
    "    hour_df = info_df[::60].copy()\n",
    "    diff_value = np.log(hour_df[name].copy()).diff().fillna(0).values\n",
    "\n",
    "    start_date = hour_df.index[0]\n",
    "    data_length = len(hour_df)\n",
    "    time_index = pd.date_range(start=start_date, periods=data_length, freq='h')\n",
    "    hour_df.index = time_index\n",
    "\n",
    "    for level in [95, 99]:\n",
    "        for window in [24 * 7 * 1, 24 * 7 * 2, 24 * 7 * 4]:\n",
    "            print(f'number: {number}, window : {window}, level : {level}')\n",
    "            ol_detect(hour_df, diff_value, window, level, number)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for number in GEO_lst:\n",
    "    name = 'longitude'\n",
    "    info_df = pd.read_csv(f'Database/{number}_new.csv', index_col=0)\n",
    "    info_df = info_df[info_df.index > '2022-12-31 23:59:59'].copy()\n",
    "    hour_df = info_df[::60].copy()\n",
    "    diff_value = np.log(hour_df[name].copy()).diff().fillna(0).values\n",
    "\n",
    "    start_date = hour_df.index[0]\n",
    "    data_length = len(hour_df)\n",
    "    time_index = pd.date_range(start=start_date, periods=data_length, freq='h')\n",
    "    hour_df.index = time_index\n",
    "\n",
    "    for level in [95, 99]:\n",
    "        for window in [24 * 7 * 1, 24 * 7 * 2, 24 * 7 * 4]:\n",
    "            print(f'number: {number}, window : {window}, level : {level}')\n",
    "            ol_detect(hour_df, diff_value, window, level, number)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 미분값"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 1, figsize=(12, 10), dpi=400, sharex=True)\n",
    "\n",
    "for i, col_name in enumerate(\n",
    "        ['altitude', 'velocity', 'apogee', 'perigee', 'inclination', 'eccentricity', 'raan', 'longitude']):\n",
    "    value = hour_df[col_name].values\n",
    "    diff_value = np.abs(hour_df[col_name].values)\n",
    "\n",
    "    axes[i].plot(hour_df.index, diff_value, color='tab:orange')\n",
    "    #axes[i].set_ylabel(col_name)\n",
    "    axes[i].legend([col_name], loc='upper left', fontsize=8)\n",
    "\n",
    "    # for point in ol_lst:\n",
    "    #     axes[i].axvline(hour_df.index[point], color='tab:red', linewidth=0.5, linestyle='--')\n",
    "    #     axes[i].scatter(hour_df.index[point], hour_df[col_name].iloc[point], color='tab:red', s=10)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
